
### 大流量
历史上的治水案例
1. 大禹治水 扩宽河道 -> 提升cpu核数和内存
2. 都江堰 引流  ->  分布式扩展
3. 三门峡和葛洲坝采用了使用了水库  ->  缓存
   
### 对抗流量常用的方法

1. 横向扩展 分流  分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。
2. 缓存 使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击。
3. 异步：在某些场景下，未处理完成之前，我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。

那么什么时候选择 Scale-up，什么时候选择 Scale-out 呢？一般来讲，在我们系统设计初期会考虑使用 Scale-up 的方式，因为这种方案足够简单，所谓能用堆砌硬件解决的问题就用硬件来解决，但是当系统并发超过了单机的极限时，我们就要使用 Scale-out 的方式。  
Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时，如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？  

1. 当单机达到极限无法满足我们的流量需求的时候，我们要考虑扩大单机资源的配置还是扩充机器（扩充机器会带来单点和节点一致性性问题也就是常说的分布式问题，那么） 怎么解决分布式问题，业内很好的中间件，zk，kakfa，都是集群，他们的原理可以帮我们给我们提供思路。

2 缓存什么时候用，cpu和内存的寻址大概在纳秒级别，磁盘的寻址在毫秒级别，千兆网卡读数据的时间在微妙级别。任何可以降低响应时间的中间存储都是缓存，cpu的二级缓存，文件有pagecache缓存